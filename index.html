<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>FluentAI - Your Personal English Tutor</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script type="importmap">
{
  "imports": {
    "@google/genai": "https://esm.run/@google/genai",
    "react": "https://aistudiocdn.com/react@^19.2.1",
    "react/": "https://aistudiocdn.com/react@^19.2.1/",
    "lucide-react": "https://aistudiocdn.com/lucide-react@^0.556.0"
  }
}
</script>
    <style>
        body { font-family: 'Inter', sans-serif; }
        @keyframes pulse-ring {
            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7); }
            70% { transform: scale(1); box-shadow: 0 0 0 20px rgba(59, 130, 246, 0); }
            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(59, 130, 246, 0); }
        }
        .animate-pulse-ring { animation: pulse-ring 2s infinite; }
        .scrollbar-hide::-webkit-scrollbar { display: none; }
        .scrollbar-hide { -ms-overflow-style: none; scrollbar-width: none; }
    </style>
</head>
<body class="bg-gray-50 min-h-screen flex flex-col font-sans text-gray-900 relative overflow-hidden">

    <!-- Background -->
    <div class="absolute inset-0 z-0 opacity-10 pointer-events-none" 
         style="background-image: url('https://picsum.photos/1920/1080?grayscale&blur=2'); background-size: cover; background-position: center;">
    </div>

    <!-- API Key Modal -->
    <div id="api-key-modal" class="fixed inset-0 z-50 flex items-center justify-center bg-black/60 backdrop-blur-sm hidden transition-opacity duration-300">
        <div class="bg-white rounded-2xl p-8 w-full max-w-md shadow-2xl mx-4 transform transition-all scale-100">
            <div class="flex flex-col items-center mb-6">
                <div class="w-12 h-12 bg-blue-100 rounded-full flex items-center justify-center mb-4 text-blue-600">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 7a2 2 0 012 2m4 0a6 6 0 01-7.743 5.743L11 17H9v2H7v2H4a1 1 0 01-1-1v-2.586a1 1 0 01.293-.707l5.964-5.964A6 6 0 1121 9z"></path></svg>
                </div>
                <h2 class="text-2xl font-bold text-gray-800 text-center">Enter Access Key</h2>
                <p class="text-gray-500 text-center mt-2 text-sm">To use FluentAI, please provide your Google Gemini API Key.</p>
            </div>
            
            <div class="space-y-4">
                <div>
                    <label for="api-key-input" class="block text-sm font-medium text-gray-700 mb-1">API Key</label>
                    <input type="password" id="api-key-input" placeholder="AIzaSy..." class="w-full p-3 border border-gray-300 rounded-xl focus:ring-2 focus:ring-blue-500 focus:border-blue-500 outline-none transition-all bg-gray-50 focus:bg-white">
                </div>
                <button id="save-api-key-btn" class="w-full bg-blue-600 text-white py-3 rounded-xl font-semibold hover:bg-blue-700 transition-colors shadow-lg shadow-blue-600/30">
                    Start Learning
                </button>
            </div>
            
            <p class="text-xs text-gray-400 mt-6 text-center text-gray-500">
                Don't have a key? <a href="https://aistudio.google.com/app/apikey" target="_blank" class="text-blue-600 hover:underline font-medium">Get one here</a>.<br>
                <span class="text-amber-600">Note: The Live API may require a paid project.</span>
            </p>
        </div>
    </div>

    <!-- Header -->
    <header class="relative z-10 w-full max-w-5xl mx-auto p-4 md:p-6 flex justify-between items-center bg-white/80 backdrop-blur-sm rounded-b-2xl shadow-sm mb-4">
        <div class="flex items-center gap-2">
            <div class="w-8 h-8 bg-blue-600 rounded-lg flex items-center justify-center text-white font-bold text-xl">F</div>
            <span class="text-2xl font-bold tracking-tight text-gray-800">FluentAI</span>
        </div>
        <div class="flex items-center gap-2">
            <!-- Mode Badge -->
            <div id="mode-badge-container" class="opacity-0 transition-opacity duration-300">
                <div id="mode-badge" class="flex items-center gap-2 px-3 py-1 rounded-full border shadow-sm">
                    <span id="mode-icon"></span>
                    <span id="mode-text" class="font-semibold tracking-wide uppercase text-xs hidden md:inline"></span>
                </div>
            </div>
            <!-- Reset Key Button -->
            <button id="reset-key-btn" class="p-2 text-gray-400 hover:text-gray-600 hover:bg-gray-100 rounded-full transition-colors" title="Change API Key">
                <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 7a2 2 0 012 2m4 0a6 6 0 01-7.743 5.743L11 17H9v2H7v2H4a1 1 0 01-1-1v-2.586a1 1 0 01.293-.707l5.964-5.964A6 6 0 1121 9z"></path></svg>
            </button>
        </div>
    </header>

    <!-- Main -->
    <main class="relative z-10 flex-1 flex flex-col items-center justify-between p-4 max-w-3xl w-full mx-auto">
        
        <!-- Intro -->
        <div id="intro" class="flex-1 flex flex-col items-center justify-center transition-opacity duration-500 absolute inset-0 z-0 p-6 pointer-events-none">
            <h1 class="text-4xl md:text-6xl font-extrabold tracking-tight mb-4 text-gray-900 text-center">
                Your Personal <span class="text-blue-600">English Tutor</span>
            </h1>
            <p class="text-lg md:text-xl text-gray-600 max-w-2xl mx-auto text-center">
                Master English through natural conversation. No text typing, just speak. Adaptive, empathetic, and real-time.
            </p>
        </div>

        <!-- Chat -->
        <div id="chat-container" class="flex-1 w-full overflow-y-auto mb-6 space-y-4 pr-2 scroll-smooth z-10 invisible" style="max-height: calc(100vh - 300px);">
            <!-- Messages injected here -->
        </div>

        <!-- Controls -->
        <div class="flex flex-col items-center w-full z-20 bg-white/90 backdrop-blur-md rounded-3xl p-6 shadow-xl border border-white/20">
            
            <!-- Speaking Indicator -->
            <div id="speaking-indicator" class="h-5 mb-2 flex items-center justify-center transition-all duration-300 opacity-0 translate-y-2">
                <span class="text-xs font-bold tracking-widest text-blue-600 uppercase bg-blue-50 px-3 py-1 rounded-full border border-blue-100 shadow-sm">
                    FluentAI is speaking
                </span>
            </div>

            <!-- Visualizer -->
            <div class="h-16 flex items-center justify-center w-full max-w-md mb-4 gap-1.5" id="visualizer">
                <div class="text-gray-400 italic text-sm" id="visualizer-placeholder">Tap the mic to start speaking...</div>
                <!-- Bars injected here -->
            </div>

            <!-- Mic Button -->
            <div class="relative group">
                <div id="mic-pulse" class="absolute inset-0 bg-blue-400 rounded-full hidden opacity-50"></div>
                <button id="mic-btn" class="relative z-10 flex items-center justify-center w-20 h-20 rounded-full shadow-2xl transition-all duration-300 focus:outline-none focus:ring-4 focus:ring-offset-2 bg-blue-600 hover:bg-blue-700 hover:scale-105">
                    <!-- Icon injected here -->
                </button>
            </div>

            <!-- Error -->
            <div id="error-msg" class="hidden mt-4 p-3 bg-red-50 border border-red-200 rounded-lg text-red-600 text-sm flex items-center gap-2 max-w-md mx-auto animate-pulse">
                <svg class="w-4 h-4 shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24"><circle cx="12" cy="12" r="10" stroke-width="2"></circle><line x1="12" y1="8" x2="12" y2="12" stroke-width="2"></line><line x1="12" y1="16" x2="12.01" y2="16" stroke-width="2"></line></svg>
                <span id="error-text"></span>
                <button id="retry-key-btn" class="text-xs bg-white border border-red-300 px-2 py-1 rounded hover:bg-red-50 hidden">Change Key</button>
            </div>
        </div>
    </main>

    <footer class="relative z-10 py-4 text-center text-gray-400 text-xs">
        <p>© 2025 FluentAI. Powered by Gemini.</p>
    </footer>

    <!-- App Logic -->
    <script type="module">
        import { GoogleGenAI } from "@google/genai";

        // --- CONFIGURATION ---
        const MANUAL_API_KEY = ''; 
        
        const MODEL_NAME = 'gemini-2.5-flash-native-audio-preview-09-2025';
        const VOICE_NAME = 'Zephyr';
        const SYSTEM_INSTRUCTION = `
Role: You are an expert, empathetic, and adaptive AI English Tutor named FluentAI. Your goal is to take students from basic to advanced levels through natural voice conversation.

--- CRITICAL BEHAVIOR ---
1.  **Adaptivity**: Detect the user's level in the first 2 sentences.
    *   *Basic*: Speak slowly, simple words, short sentences.
    *   *Advanced*: Normal pace, idioms, complex topics.
2.  **Fallback Language**: If the user speaks Portuguese (e.g., "Não entendi"), briefly explain in Portuguese, then IMMEDIATELY switch back to English.
3.  **15-Second Rule**: Keep responses under 15 seconds. Be concise.
4.  **Always End with a Question**: Never end a turn with a statement. Pass the ball back.
5.  **No Text Formatting**: Speak naturally. Do not read markdown.
6.  **No Babbling**: Avoid filler phrases like "That is interesting".

--- MODES & TOOLS ---
You have access to a tool called "setTeachingMode". You MUST call this tool when your teaching style changes.
*   **Conversation Mode** (Default): Chat about life, hobbies.
*   **Correction Mode**: Triggered by grammar mistakes. Gently correct, then ask to repeat.
*   **Explanation Mode**: Triggered when explaining a concept or translating.

--- EXAMPLES ---
User: "Hi. Me name is Joao."
You (Call tool setTeachingMode('Correction Mode')): "Hello João! In English, we say 'My name is João'. Can you try saying that?"

User: "My name is João."
You (Call tool setTeachingMode('Conversation Mode')): "Perfect! Where are you from, João?"
`;

        // --- STATE ---
        const state = {
            isConnected: false,
            isSpeaking: false,
            mode: 'Ready to Start',
            volume: 0,
            messages: []
        };

        const TeachingMode = {
            CONVERSATION: 'Conversation Mode',
            CORRECTION: 'Correction Mode',
            EXPLANATION: 'Explanation Mode',
            IDLE: 'Ready to Start'
        };

        // --- DOM ELEMENTS ---
        const els = {
            micBtn: document.getElementById('mic-btn'),
            micPulse: document.getElementById('mic-pulse'),
            visualizer: document.getElementById('visualizer'),
            visualizerPlaceholder: document.getElementById('visualizer-placeholder'),
            intro: document.getElementById('intro'),
            chat: document.getElementById('chat-container'),
            error: document.getElementById('error-msg'),
            errorText: document.getElementById('error-text'),
            retryKeyBtn: document.getElementById('retry-key-btn'),
            indicator: document.getElementById('speaking-indicator'),
            modeBadgeContainer: document.getElementById('mode-badge-container'),
            modeBadge: document.getElementById('mode-badge'),
            modeText: document.getElementById('mode-text'),
            modeIcon: document.getElementById('mode-icon'),
            // Modal Elements
            apiKeyModal: document.getElementById('api-key-modal'),
            apiKeyInput: document.getElementById('api-key-input'),
            saveApiKeyBtn: document.getElementById('save-api-key-btn'),
            resetKeyBtn: document.getElementById('reset-key-btn')
        };

        // --- ICONS (SVG Strings) ---
        const icons = {
            mic: '<svg class="w-8 h-8 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" stroke-width="2"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>',
            micOff: '<svg class="w-8 h-8 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" stroke-width="2"><line x1="1" y1="1" x2="23" y2="23"></line><path d="M9 9v3a3 3 0 0 0 5.12 2.12M15 9.34V4a3 3 0 0 0-5.94-.6"></path><path d="M17 16.95A7 7 0 0 1 5 12v-2m14 0v2a7 7 0 0 1-.11 1.23"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>',
            conversation: '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"></path></svg>',
            correction: '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path></svg>',
            explanation: '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path></svg>',
            default: '<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>'
        };

        // --- API KEY HANDLING ---
        function getApiKey() {
            if (MANUAL_API_KEY) return MANUAL_API_KEY;
            try { if (process.env.API_KEY) return process.env.API_KEY; } catch(e) {}
            return localStorage.getItem('fluentai_api_key');
        }

        function promptForApiKey() {
            els.apiKeyModal.classList.remove('hidden');
        }

        function clearApiKey() {
            localStorage.removeItem('fluentai_api_key');
            promptForApiKey();
        }

        // --- VISUALIZER LOGIC ---
        let visualizerBars = [];
        let visualizerTick = 0;
        let visualizerReqId;

        function initVisualizer() {
            els.visualizer.innerHTML = '';
            visualizerBars = [];
            for (let i = 0; i < 5; i++) {
                const bar = document.createElement('div');
                bar.className = 'w-2.5 rounded-full transition-all duration-75 bg-gray-400';
                bar.style.height = '4px';
                els.visualizer.appendChild(bar);
                visualizerBars.push(bar);
            }
        }

        function updateVisualizerColor() {
            let colorClass = 'bg-gray-400';
            if (state.mode === TeachingMode.CONVERSATION) colorClass = 'bg-blue-500';
            else if (state.mode === TeachingMode.CORRECTION) colorClass = 'bg-yellow-500';
            else if (state.mode === TeachingMode.EXPLANATION) colorClass = 'bg-purple-500';
            
            visualizerBars.forEach(bar => {
                bar.className = `w-2.5 rounded-full transition-all duration-75 ${colorClass}`;
            });
        }

        function animateVisualizer() {
            if (!state.isConnected) return;

            if (state.isSpeaking) {
                visualizerTick += 0.2;
                visualizerBars.forEach((bar, index) => {
                    const base = Math.sin(visualizerTick + index * 0.8);
                    const secondary = Math.cos(visualizerTick * 0.5 + index * 0.5);
                    const normalized = ((base + secondary) / 2 + 1) / 2;
                    const height = 12 + normalized * 36;
                    bar.style.height = `${height}px`;
                });
            } else {
                const v = Math.min(Math.max(state.volume, 0.05), 1);
                const distribution = [0.4, 0.7, 1.0, 0.7, 0.4];
                visualizerBars.forEach((bar, index) => {
                    const scale = distribution[index];
                    const noise = Math.random() * 4;
                    const height = 8 + (v * 50 * scale) + noise;
                    bar.style.height = `${height}px`;
                });
            }
            visualizerReqId = requestAnimationFrame(animateVisualizer);
        }

        // --- AUDIO UTILS ---
        function base64ToBytes(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
            return bytes;
        }

        function bytesToBase64(bytes) {
            let binary = '';
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) binary += String.fromCharCode(bytes[i]);
            return btoa(binary);
        }

        function float32ToInt16(float32) {
            const int16 = new Int16Array(float32.length);
            for (let i = 0; i < float32.length; i++) {
                const s = Math.max(-1, Math.min(1, float32[i]));
                int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return int16;
        }

        async function decodeAudioData(data, ctx, sampleRate = 24000) {
            const dataInt16 = new Int16Array(data.buffer);
            const frameCount = dataInt16.length;
            const buffer = ctx.createBuffer(1, frameCount, sampleRate);
            const channelData = buffer.getChannelData(0);
            for (let i = 0; i < frameCount; i++) {
                channelData[i] = dataInt16[i] / 32768.0;
            }
            return buffer;
        }

        // --- LIVE SESSION LOGIC ---
        let audioContextInput;
        let audioContextOutput;
        let session;
        let processor;
        let inputSource;
        let mediaStream;
        let nextStartTime = 0;
        let scheduledSources = new Set();

        async function connect() {
            try {
                setError(null);
                
                const apiKey = getApiKey();
                
                if (!apiKey) {
                    promptForApiKey();
                    return; 
                }

                const ai = new GoogleGenAI({ apiKey });
                
                // Init Audio with resuming check
                const AudioContext = window.AudioContext || window.webkitAudioContext;
                audioContextInput = new AudioContext({ sampleRate: 16000 });
                audioContextOutput = new AudioContext({ sampleRate: 24000 });

                // CRITICAL: Resume audio contexts on user interaction to prevent "interrupted" or silent failures
                await audioContextInput.resume();
                await audioContextOutput.resume();

                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                session = await ai.live.connect({
                    model: MODEL_NAME,
                    config: {
                        responseModalities: ['AUDIO'],
                        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: VOICE_NAME } } },
                        systemInstruction: SYSTEM_INSTRUCTION,
                        tools: [{ functionDeclarations: [{
                            name: 'setTeachingMode',
                            description: 'Updates the current teaching mode.',
                            parameters: {
                                type: 'OBJECT',
                                properties: {
                                    mode: { type: 'STRING', enum: Object.values(TeachingMode) }
                                },
                                required: ['mode']
                            }
                        }] }],
                        inputAudioTranscription: {},
                        outputAudioTranscription: {}
                    },
                    callbacks: {
                        onopen: () => {
                            setConnected(true);
                            setMode(TeachingMode.CONVERSATION);
                        },
                        onmessage: handleMessage,
                        onclose: () => {
                            console.log("Closed");
                            disconnect();
                        },
                        onerror: (e) => {
                            console.error(e);
                            // Detect if error might be auth related
                            setError("Connection Failed. API Key might be invalid or quota exceeded.");
                            els.retryKeyBtn.classList.remove('hidden');
                            disconnect();
                        }
                    }
                });

                startAudioInput(session);

            } catch (e) {
                console.error(e);
                setError(e.message || "Failed to connect");
                els.retryKeyBtn.classList.remove('hidden');
                disconnect();
            }
        }

        function disconnect() {
            setConnected(false);
            setSpeaking(false);
            setMode(TeachingMode.IDLE);
            state.volume = 0;

            if (session) {
                try { session.close(); } catch(e) {}
                session = null;
            }
            if (processor) { processor.disconnect(); processor = null; }
            if (inputSource) { inputSource.disconnect(); inputSource = null; }
            if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
            if (audioContextInput) { audioContextInput.close(); audioContextInput = null; }
            if (audioContextOutput) { audioContextOutput.close(); audioContextOutput = null; }
            
            scheduledSources.forEach(s => { try{s.stop()}catch(e){} });
            scheduledSources.clear();
            nextStartTime = 0;
        }

        function startAudioInput(currentSession) {
            if (!audioContextInput || !mediaStream) return;
            
            inputSource = audioContextInput.createMediaStreamSource(mediaStream);
            processor = audioContextInput.createScriptProcessor(4096, 1, 1);
            
            processor.onaudioprocess = (e) => {
                const inputData = e.inputBuffer.getChannelData(0);
                
                // Volume calc
                let sum = 0;
                for (let i = 0; i < inputData.length; i++) sum += inputData[i] * inputData[i];
                state.volume = Math.sqrt(sum / inputData.length) * 5; 

                const pcm16 = float32ToInt16(inputData);
                const base64Data = bytesToBase64(new Uint8Array(pcm16.buffer));

                currentSession.sendRealtimeInput({
                    media: { mimeType: 'audio/pcm;rate=16000', data: base64Data }
                });
            };

            inputSource.connect(processor);
            processor.connect(audioContextInput.destination);
        }

        async function handleMessage(message) {
            // Tool Calls
            if (message.toolCall) {
                for (const fc of message.toolCall.functionCalls) {
                    if (fc.name === 'setTeachingMode') {
                        setMode(fc.args.mode);
                        session.sendToolResponse({
                            functionResponses: { id: fc.id, name: fc.name, response: { result: "ok" } }
                        });
                    }
                }
            }

            // Audio Output
            const base64Audio = message.serverContent?.modelTurn?.parts?.[0]?.inlineData?.data;
            if (base64Audio && audioContextOutput) {
                setSpeaking(true);
                const ctx = audioContextOutput;
                const now = ctx.currentTime;
                if (nextStartTime < now) nextStartTime = now;

                try {
                    const buffer = await decodeAudioData(base64ToBytes(base64Audio), ctx);
                    const source = ctx.createBufferSource();
                    source.buffer = buffer;
                    source.connect(ctx.destination);
                    source.start(nextStartTime);
                    nextStartTime += buffer.duration;
                    
                    scheduledSources.add(source);
                    source.onended = () => {
                        scheduledSources.delete(source);
                        if (scheduledSources.size === 0) setSpeaking(false);
                    };
                } catch(e) { console.error("Decode error", e); }
            }

            if (message.serverContent?.interrupted) {
                scheduledSources.forEach(s => { try{s.stop()}catch(e){} });
                scheduledSources.clear();
                nextStartTime = 0;
                setSpeaking(false);
            }

            // Transcriptions
            const serverContent = message.serverContent;
            if (serverContent) {
                const inputTx = serverContent.inputTranscription?.text;
                const outputTx = serverContent.outputTranscription?.text;
                if (inputTx || outputTx) {
                    addMessage(inputTx ? 'user' : 'model', inputTx || outputTx, false);
                }
                if (serverContent.turnComplete) {
                     markLastMessageFinal();
                }
            }
        }

        // --- UI UPDATES ---

        function render() {
            // Mic Button
            els.micBtn.innerHTML = state.isConnected ? icons.micOff : icons.mic;
            els.micBtn.className = `relative z-10 flex items-center justify-center w-20 h-20 rounded-full shadow-2xl transition-all duration-300 focus:outline-none focus:ring-4 focus:ring-offset-2 ${state.isConnected ? 'bg-red-500 hover:bg-red-600 focus:ring-red-500 rotate-0' : 'bg-blue-600 hover:bg-blue-700 focus:ring-blue-600 hover:scale-105'}`;
            
            if (state.isConnected) {
                els.micPulse.classList.remove('hidden');
                els.micPulse.classList.add('animate-pulse-ring');
                els.intro.classList.add('opacity-0');
                els.chat.classList.remove('invisible');
                els.modeBadgeContainer.classList.remove('opacity-0');
                
                els.visualizerPlaceholder.classList.add('hidden');
                if (visualizerBars.length === 0) {
                    initVisualizer();
                    updateVisualizerColor();
                    animateVisualizer();
                }
            } else {
                els.micPulse.classList.add('hidden');
                els.micPulse.classList.remove('animate-pulse-ring');
                if (state.messages.length === 0) {
                   els.intro.classList.remove('opacity-0');
                   els.chat.classList.add('invisible');
                }
                els.modeBadgeContainer.classList.add('opacity-0');
                
                if (visualizerReqId) cancelAnimationFrame(visualizerReqId);
                els.visualizer.innerHTML = '';
                visualizerBars = [];
                els.visualizerPlaceholder.classList.remove('hidden');
            }

            // Speaking Indicator
            if (state.isConnected && state.isSpeaking) {
                els.indicator.classList.remove('opacity-0', 'translate-y-2');
                els.indicator.classList.add('opacity-100', 'translate-y-0');
            } else {
                els.indicator.classList.add('opacity-0', 'translate-y-2');
                els.indicator.classList.remove('opacity-100', 'translate-y-0');
            }
        }

        function setConnected(val) {
            state.isConnected = val;
            render();
        }

        function setSpeaking(val) {
            state.isSpeaking = val;
            render(); 
            // Note: visualizer loop checks state directly
        }

        function setError(msg) {
            if (msg) {
                els.errorText.textContent = msg;
                els.error.classList.remove('hidden');
            } else {
                els.error.classList.add('hidden');
                els.retryKeyBtn.classList.add('hidden');
            }
        }

        function setMode(mode) {
            state.mode = mode;
            updateVisualizerColor();
            
            // Update Badge
            els.modeText.textContent = mode;
            let icon = icons.default;
            let colorClass = 'text-gray-600 bg-gray-100 border-gray-200';

            if (mode === TeachingMode.CONVERSATION) {
                icon = icons.conversation;
                colorClass = 'text-blue-600 bg-blue-100 border-blue-200';
            } else if (mode === TeachingMode.CORRECTION) {
                icon = icons.correction;
                colorClass = 'text-yellow-700 bg-yellow-100 border-yellow-200';
            } else if (mode === TeachingMode.EXPLANATION) {
                icon = icons.explanation;
                colorClass = 'text-purple-700 bg-purple-100 border-purple-200';
            }

            els.modeIcon.innerHTML = icon;
            els.modeBadge.className = `flex items-center gap-2 px-3 py-1 rounded-full border shadow-sm ${colorClass}`;
        }

        function addMessage(role, text, isFinal) {
            const lastMsg = state.messages[state.messages.length - 1];
            
            // If streaming the same turn, update previous message
            if (lastMsg && lastMsg.role === role && !lastMsg.isFinal) {
                lastMsg.text += text;
                const el = document.getElementById(lastMsg.id);
                if (el) el.textContent = lastMsg.text;
            } else {
                const id = Date.now().toString() + role;
                state.messages.push({ id, role, text, isFinal });
                
                const wrapper = document.createElement('div');
                wrapper.className = `flex w-full ${role === 'user' ? 'justify-end' : 'justify-start'}`;
                
                const bubble = document.createElement('div');
                bubble.id = id;
                bubble.className = `max-w-[80%] rounded-2xl px-5 py-3 shadow-sm text-sm md:text-base leading-relaxed ${
                  role === 'user' 
                    ? 'bg-blue-600 text-white rounded-br-none' 
                    : 'bg-white border border-gray-100 text-gray-800 rounded-bl-none'
                }`;
                bubble.textContent = text;
                
                wrapper.appendChild(bubble);
                els.chat.appendChild(wrapper);
            }
            els.chat.scrollTop = els.chat.scrollHeight;
        }

        function markLastMessageFinal() {
             const lastMsg = state.messages[state.messages.length - 1];
             if (lastMsg) lastMsg.isFinal = true;
        }

        // --- INIT ---
        els.micBtn.innerHTML = icons.mic;
        els.micBtn.addEventListener('click', () => {
            if (state.isConnected) disconnect();
            else connect();
        });

        // Modal Handlers
        els.saveApiKeyBtn.addEventListener('click', () => {
            const val = els.apiKeyInput.value.trim();
            if (val) {
                localStorage.setItem('fluentai_api_key', val);
                els.apiKeyModal.classList.add('hidden');
                connect(); // Try connecting again
            }
        });
        
        els.resetKeyBtn.addEventListener('click', clearApiKey);
        els.retryKeyBtn.addEventListener('click', clearApiKey);

    </script>
</body>
</html>